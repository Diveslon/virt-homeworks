# Домашнее задание к занятию "6.6. Troubleshooting"

## Задача 1

Перед выполнением задания ознакомьтесь с документацией по [администрированию MongoDB](https://docs.mongodb.com/manual/administration/).

Пользователь (разработчик) написал в канал поддержки, что у него уже 3 минуты происходит CRUD операция в MongoDB и её 
нужно прервать. 

Вы как инженер поддержки решили произвести данную операцию:
- напишите список операций, которые вы будете производить для остановки запроса пользователя
- предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB
### Ответ
- напишите список операций, которые вы будете производить для остановки запроса пользователя

Сначала найдём запросы больше 180 секунд в базе database
```
db.currentOp(
   {
     "active" : true,
     "secs_running" : { "$gt" : 180 },
     "ns" : /^database\./
   }
)
```
Выберем нужный OpID и "убьём" его
```
	db.killOp(<OpID>)
```
- предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB

1. Чтобы заткнуть проблему можно ограничить время выполнения запросов
2. Чтобы разобраться следует загнать этот запрос в explain и разобраться, где и что торомозит.



## Задача 2

Перед выполнением задания познакомьтесь с документацией по [Redis latency troobleshooting](https://redis.io/topics/latency).

Вы запустили инстанс Redis для использования совместно с сервисом, который использует механизм TTL. 
Причем отношение количества записанных key-value значений к количеству истёкших значений есть величина постоянная и
увеличивается пропорционально количеству реплик сервиса. 

При масштабировании сервиса до N реплик вы увидели, что:
- сначала рост отношения записанных значений к истекшим
- Redis блокирует операции записи

Как вы думаете, в чем может быть проблема?

### Ответ
В Redis есть два способа очистить просроченные записи: 
- Если вы запрашиваете просроченный объект, Redis его удаляет в этот же момент (пассивный механизм).
- Активный механизм очистки “устаревших” данных в бекграунде. Он работает постоянно.
При использовании автивного режима Redis 10 раз в секунду проделывает следующее:
1. Тестирует 20 случайных ключей из всего набора ключей в БД с проставленным TTL.
2. Удаляет все ключи с просроченным сроком жизни.
3. Если более 25% ключей удалены, возвращаемся к пункту 1.

И тут мы можем столкнуться с проблемой "долгоживущих" ключей. Большое количество долгоживущих ключей могло влиять на качество очистки ключей в целом: Redis берёт 20 случайных ключей, большая часть из которых относилася к «долгожителям». Алгоритм начинает часто недобирать 25% удаленных ключей для запуска следующей итерации.

Или второй вариант:При большом количестве ключей процесс проверки зациклится и мы ощутим задержки, а потом и вовсе не будут приниматься данные на запись, если появятся истекшие записи более 25% по отношению ко всем. 
 
## Задача 3

Перед выполнением задания познакомьтесь с документацией по [Common Mysql errors](https://dev.mysql.com/doc/refman/8.0/en/common-errors.html).

Вы подняли базу данных MySQL для использования в гис-системе. При росте количества записей, в таблицах базы,
пользователи начали жаловаться на ошибки вида:
```python
InterfaceError: (InterfaceError) 2013: Lost connection to MySQL server during query u'SELECT..... '
```

Как вы думаете, почему это начало происходить и как локализовать проблему?

Какие пути решения данной проблемы вы можете предложить?

### Ответ
Согласно документации, подобное сообщение может появиться при выборке таблицы с очень большим количеством строк. В этом случае следует увеличить значение параметра net_read_timeout с 30 по умолчанию до 60.
Если не помогло, то второй вариант может возникнуть проблема со значениями BLOB, превышающими max_allowed_packet, что может вызвать эту ошибку. В данной ситуации следует увеличить значение max_allowed_packet.

## Задача 4

Перед выполнением задания ознакомтесь со статьей [Common PostgreSQL errors](https://www.percona.com/blog/2020/06/05/10-common-postgresql-errors/) из блога Percona.

Вы решили перевести гис-систему из задачи 3 на PostgreSQL, так как прочитали в документации, что эта СУБД работает с 
большим объемом данных лучше, чем MySQL.

После запуска пользователи начали жаловаться, что СУБД время от времени становится недоступной. В dmesg вы видите, что:

`postmaster invoked oom-killer`

Как вы думаете, что происходит?

Как бы вы решили данную проблему?

### Ответ ( с доработкой после замечаний)
Когда у сервера или процесса заканчивается память, Linux предлагает 2 пути решения: обрушить всю систему или завершить процесс (приложение), который съедает память. Лучше, конечно, завершить процесс и спасти ОС от аварийного завершения. В двух словах, Out-Of-Memory Killer — это процесс, который завершает приложение, чтобы спасти ядро от сбоя. Он жертвует приложением, чтобы сохранить работу ОС. 
Out-Of-Memory Killer говорит о том, что процесс postgres был уничтожен из-за нехватки памяти. Хотя существующие подключения к базе данных будут работать по-прежнему, новые подключения приниматься не будут. Чтобы восстановить работу сервера, PostgreSQL придётся перезапустить.
Решить возникающую проблему возможно двумя путями:
1. Необходимо проверить настройки сервиса PostgreSQL в части памяти, внести корректировки.
2. Выделять оперативную память по факту, и этим поведением управляет параметр ядра Linux. За это отвечает переменная vm.overcommit_memory.

Если памяти не хватает по вине самого PostgreSQL, эту проблему можно решить, изменив конфигурацию сервера. В некоторых случаях может помочь уменьшение конфигурационных параметров, связанных с памятью, а именно shared_buffers и work_mem. В других случаях проблема может возникать, потому что разрешено слишком много подключений к самому серверу баз данных. Чаще всего в такой ситуации стоит уменьшить число подключений max_connections и организовать внешний пул соединений.

«Чрезмерное выделение» памяти можно предотвратить, изменив поведение ядра.
Для vm.overcommit_memory можно указывать следующие значения:
0: ядро само решает, стоит ли резервировать слишком много памяти. Это значение по умолчанию в большинстве версий Linux.
1: ядро всегда будет резервировать лишнюю память. Это рискованно, ведь память может закончиться, потому что, скорее всего, однажды процессы затребуют положенное.
2: ядро не будет резервировать больше памяти, чем указано в параметре overcommit_ratio.

В этом параметре указывается процент памяти, для которого допустимо избыточное резервирование. Если для него нет места, память не выделяется, в резервировании будет отказано. Это самый безопасный вариант, рекомендованный для PostgreSQL.

---

### Как cдавать задание

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---
